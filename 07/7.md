# 节点调度

1. nodeName 指定

```
$ k apply -f nodeName.yaml 
pod/configmap-volume-pod created
(base) 
zq102@MSI MINGW64 /d/desktop/gitDemo/k8s/07 (master)
$ k get po -owide
NAME                      READY   STATUS              RESTARTS        AGE     IP           NODE           NOMINATED NODE   READINESS GATES
centos-7f8f96cc85-gwdmj   0/1     Running             0               5h30m   10.244.2.9   kind-worker    <none>           <none>
configmap-volume-pod      0/1     ContainerCreating   0               5s      <none>       kind-worker    <
```

2. nodeSelector 选择

```
$ k apply -f nodeSelector.yaml 


$ k get po
NAME                      READY   STATUS    RESTARTS        AGE
centos-7f8f96cc85-gwdmj   0/1     Running   0               5h39m
nginx-7769f8f85b-d4tbh    1/1     Running   1 (7h44m ago)   23h
node-selector             0/1     Pending   0               75s
# 这里一直在调度 没有符合条件的标签


$ k describe po node-selector
......
node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age   From               Message
  ----     ------            ----  ----               -------
  Warning  FailedScheduling  16s   default-scheduler  0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.



$ k get po -owide
NAME                      READY   STATUS         RESTARTS        AGE     IP           NODE           NOMINATED NODE   READINESS GATES
centos-7f8f96cc85-gwdmj   0/1     Running        0               5h40m   10.244.2.9   kind-worker    <none>           <none>
nginx-7769f8f85b-d4tbh    1/1     Running        1 (7h46m ago)   23h     10.244.1.2   kind-worker2   <none>           <none>
node-selector             0/1     ErrImagePull   0               3m2s    10.244.1.5   kind-worker2   <none>           <none>

# 删除lable
$ k label node kind-worker2  node-
node/kind-worker2 unlabeled


$ k get po -owide
NAME                      READY   STATUS    RESTARTS        AGE     IP           NODE           NOMINATED NODE   READINESS GATES
centos-7f8f96cc85-gwdmj   0/1     Running   0               5h43m   10.244.2.9   kind-worker    <none>           <none>
nginx-7769f8f85b-d4tbh    1/1     Running   1 (7h49m ago)   23h     10.244.1.2   kind-worker2   <none>           <none>
node-selector             1/1     Running   0               6m10s   10.244.1.5   kind-worker2   <none>           <none>


$ k label node kind-worker node=ssd
node/kind-worker labeled



$ k get po -owide
NAME                      READY   STATUS    RESTARTS        AGE     IP           NODE           NOMINATED NODE   READINESS GATES
centos-7f8f96cc85-gwdmj   0/1     Running   0               5h44m   10.244.2.9   kind-worker    <none>           <none>
nginx-7769f8f85b-d4tbh    1/1     Running   1 (7h50m ago)   23h     10.244.1.2   kind-worker2   <none>           <none>
node-selector             1/1     Running   0               6m57s   10.244.1.5   kind-worker2   <none>           <none>


```


## 亲和性和反亲和性
(link)[https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/]


```
apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - antarctica-east1
            - antarctica-west1
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: another-node-label-key
            operator: In
            values:
            - another-node-label-value
  containers:
  - name: with-node-affinity
    image: registry.k8s.io/pause:3.8

```


## 污点和容忍度
(link)[https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/]

taint 是针对node的  toleration 是针对pod的



```
kubectl taint nodes node1 key1=value1:NoSchedule
```
 
例子: control-plane.example.yaml node 中有 taint pod etcd.example.yaml 中有 toleration


```
......
spec:
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
......

......
spec:
  tolerations:
  - effect: NoExecute
    operator: Exists
......


```
例子
```
# 这里使用 NoExecute 才会驱逐 NoSchedule 不会驱逐
$ k taint node kind-worker2 a=bb:NoExecute
node/kind-worker2 tainted

# 正在驱逐重启
$ k get po -owide
NAME                      READY   STATUS        RESTARTS   AGE     IP            NODE           NOMINATED NODE   READINESS GATES
centos-7f8f96cc85-gwdmj   0/1     Running       0          6h22m   10.244.2.9    kind-worker    <none>           <none>
nginx-7769f8f85b-8n6bn    1/1     Running       0          10s     10.244.2.11   kind-worker    <none>           <none>
node-selector             1/1     Terminating   0          44m     10.244.1.5    kind-worker2   <none>           <none>


$ k get node kind-worker2 -oyaml
......
spec:
  podCIDR: 10.244.1.0/24
  podCIDRs:
  - 10.244.1.0/24
  providerID: kind://docker/kind/kind-worker2
  taints:
  - effect: NoExecute
    key: a
    value: bb

    
$ k taint nodes kind-worker2 a-
node/kind-worker2 untainted


$ k get node kind-worker2 -oyaml
......
spec:
  podCIDR: 10.244.1.0/24
  podCIDRs:
  - 10.244.1.0/24
  providerID: kind://docker/kind/kind-worker2

```


## 手动冻结

```

root@kind-control-plane:/# k cordon kind-worker2
node/kind-worker2 cordoned
root@kind-control-plane:/# k get nodes       
NAME                 STATUS                     ROLES           AGE     VERSION
kind-control-plane   NotReady                   control-plane   3d22h   v1.33.1
kind-worker          Ready                      <none>          3d22h   v1.33.1
kind-worker2         Ready,SchedulingDisabled   <none>          3d22h   v1.33.1

root@kind-control-plane:/# curl 10.89.0.3:32481
<!DOCTYPE html>
<html>
......

root@kind-control-plane:/# k drain kind-worker2
node/kind-worker2 already cordoned
error: unable to drain node "kind-worker2" due to error: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kindnet-wq528, kube-system/kube-proxy-l2jfr, continuing command...
There are pending nodes to be drained:
 kind-worker2
cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kindnet-wq528, kube-system/kube-proxy-l2jfr

root@kind-control-plane:/# k drain kind-worker2 --ignore-daemonsets
node/kind-worker2 already cordoned
Warning: ignoring DaemonSet-managed Pods: kube-system/kindnet-wq528, kube-system/kube-proxy-l2jfr
evicting pod local-path-storage/local-path-provisioner-7dc846544d-h5n6z
evicting pod default/nginx-db7574cdc-fj667
evicting pod kube-system/coredns-674b8bbfcf-9j6w6
pod/nginx-db7574cdc-fj667 evicted
pod/local-path-provisioner-7dc846544d-h5n6z evicted
pod/coredns-674b8bbfcf-9j6w6 evicted
node/kind-worker2 drained

root@kind-control-plane:/# k get po -owide
NAME                    READY   STATUS    RESTARTS      AGE     IP           NODE          NOMINATED NODE   READINESS GATES
nginx-db7574cdc-9ljcv   1/1     Running   2 (55m ago)   3d22h   10.244.1.3   kind-worker   <none>           <none>
nginx-db7574cdc-lbngc   0/1     Pending   0             44s     <none>       <none>        <none>           <none>


root@kind-control-plane:/# k get deploy
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/2     2            1           3d22h

# 这里并没有驱逐后 pod漂到其他节点？ 一直是pending的状态


root@kind-control-plane:/# k get po   
NAME                    READY   STATUS    RESTARTS       AGE
nginx-db7574cdc-9ljcv   1/1     Running   2 (103m ago)   3d22h
nginx-db7574cdc-lbngc   0/1     Pending   0              48m
root@kind-control-plane:/# k describe po nginx-db7574cdc-lbngc
Name:             nginx-db7574cdc-lbngc
Namespace:        default
......
                          node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age                From               Message
  ----     ------            ----               ----               -------
  Warning  FailedScheduling  48m                default-scheduler  0/3 nodes are available: 1 node(s) didn't have free ports for the requested pod ports, 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) were unschedulable. preemption: 0/3 nodes are available: 1 No preemption victims found for incoming pod, 2 Preemption is not helpful for scheduling.
  Warning  FailedScheduling  18m (x7 over 48m)  default-scheduler  0/3 nodes are available: 1 node(s) didn't have free ports for the requested pod ports, 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) were unschedulable. preemption: 0/3 nodes are available: 1 No preemption victims found for incoming pod, 2 Preemption is not helpful for scheduling. 


# 解冻

root@kind-control-plane:/# k uncordon kind-worker2
node/kind-worker2 uncordoned
root@kind-control-plane:/# k get nodes
NAME                 STATUS     ROLES           AGE     VERSION
kind-control-plane   NotReady   control-plane   3d23h   v1.33.1
kind-worker          Ready      <none>          3d23h   v1.33.1
kind-worker2         Ready      <none>          3d23h   v1.33.1
root@kind-control-plane:/# k get po   
```
